{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source\n",
    "https://thinkinfi.com/warp-perspective-opencv/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import cv2  # OpenCV - change image\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "BASE_FP = config[\"FILES\"][\"default_path\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    \"\"\"This is better than our first pass of resize_window\"\"\"\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe(img, clipLimit: float, tileGridSize):\n",
    "    \"\"\"Address glare and bright spots\n",
    "\n",
    "    A bright photo will have all its pixels confined to a relatively high value. Picture a histogram that is thin and tall. CLAHE will essentially normalize it, spreading the values so the histogram is shorter and wider.\n",
    "    \"\"\"\n",
    "    clahe_ = cv2.createCLAHE(clipLimit, tileGridSize)\n",
    "\n",
    "    new_img = clahe_.apply(img)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corners(morph, original):\n",
    "    \"\"\"\n",
    "    Thanks https://stackoverflow.com/questions/60941012/how-do-i-find-corners-of-a-paper-when-there-are-printed-corners-lines-on-paper-i\n",
    "    Algorithm above\n",
    "    1. Apply grayscale\n",
    "    2. Apply blur\n",
    "    3. Apply threshold (i.e. black & white)\n",
    "    4. Apply morphology\n",
    "    5. Find contours\n",
    "    6. Approximate polygon -> 4 vertices that represent corners\n",
    "\n",
    "    To allow flexibility, we'll skip steps 1-4. Main takeaway is to provide an image where, as best as possible, only 4 contours can be found. Typically will be a black & white image\n",
    "    \"\"\"\n",
    "\n",
    "    # get largest contour\n",
    "    contours = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "    area_thresh = 0\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > area_thresh:\n",
    "            area_thresh = area\n",
    "            big_contour = c\n",
    "\n",
    "    # get perimeter and approximate a polygon\n",
    "    peri = cv2.arcLength(big_contour, True)\n",
    "    # note that approxPolyDP looks for any polygon, not specifically a rectangle\n",
    "    corners = cv2.approxPolyDP(big_contour, 0.04 * peri, True)\n",
    "\n",
    "    corners = [corner[0] for corner in corners]\n",
    "\n",
    "    # Add blue circles onto image\n",
    "    # for corner in corners:\n",
    "    #     x, y = corner.ravel()\n",
    "    #     cv2.circle(original, (x, y), 50, (255, 0, 0), -1)\n",
    "    resize = resize_with_aspect_ratio(original, 300, 200)\n",
    "    cv2.imshow(\"blue corners\", resize)\n",
    "\n",
    "    return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAngle(a, b, c):\n",
    "    # https://manivannan-ai.medium.com/find-the-angle-between-three-points-from-2d-using-python-348c513e2cd\n",
    "    ang = math.degrees(\n",
    "        math.atan2(c[1] - b[1], c[0] - b[0]) - math.atan2(a[1] - b[1], a[0] - b[0])\n",
    "    )\n",
    "    return ang + 360 if ang < 0 else ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_corners_angle(corners):\n",
    "    best_corners = set()\n",
    "    n = len(corners)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            for k in range(j + 1, n):\n",
    "                angle = getAngle(corners[i], corners[j], corners[k])\n",
    "\n",
    "                if abs(angle - 90) < 2:\n",
    "                    best_corners.add(tuple(corners[i]))\n",
    "                    best_corners.add(tuple(corners[j]))\n",
    "                    best_corners.add(tuple(corners[k]))\n",
    "\n",
    "    if len(best_corners) != 4:\n",
    "        print(f\"After checking the angles, cannot find exactly 4 corners\")\n",
    "        return corners\n",
    "\n",
    "    # return as list because sets are not ordered\n",
    "    return list(best_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(vertices):\n",
    "    # https://stackoverflow.com/questions/66916409/python-find-most-upper-left-coordinate-and-corners-in-opencv-numpy\n",
    "    # order: [tl, tr, bl, br]\n",
    "    sums = [sum(vertex) for vertex in vertices]\n",
    "    tl_sum = min(sums)\n",
    "    br_sum = max(sums)\n",
    "\n",
    "    for vertex in vertices:\n",
    "        sum_ = sum(vertex)\n",
    "        if sum_ == tl_sum:\n",
    "            tl = vertex\n",
    "        elif sum_ == br_sum:\n",
    "            br = vertex\n",
    "\n",
    "    diffs = [(vertex[1] - vertex[0]) for vertex in vertices]\n",
    "    tr_diff = min(diffs)\n",
    "    bl_diff = max(diffs)\n",
    "\n",
    "    for vertex in vertices:\n",
    "        diff = vertex[1] - vertex[0]\n",
    "        if diff == tr_diff:\n",
    "            tr = vertex\n",
    "        elif diff == bl_diff:\n",
    "            bl = vertex\n",
    "\n",
    "    print(f\"ordered: {[tl, tr, bl, br]}\")\n",
    "    return [tl, tr, bl, br]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_perspective(img, corners):\n",
    "    height, width, *_ = img.shape\n",
    "    print(f\"{width=}, {height=}\")\n",
    "    # Get top-left, top-right, bottom-left, bottom-right points\n",
    "    # tl, bl, br, tr = corners\n",
    "    tl, tr, bl, br = corners\n",
    "\n",
    "    point_matrix = np.float32([tl, tr, bl, br])\n",
    "\n",
    "    # cv2.circle(img, (tl[0], tl[1]), 50, (0, 0, 255), cv2.FILLED)\n",
    "    # cv2.circle(img, (tr[0], tr[1]), 50, (0, 255, 0), cv2.FILLED)\n",
    "    # cv2.circle(img, (bl[0], bl[1]), 50, (255, 0, 0), cv2.FILLED)\n",
    "    # cv2.circle(img, (br[0], br[1]), 50, (0, 0, 0), cv2.FILLED)\n",
    "\n",
    "    converted_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "    perspective_transform = cv2.getPerspectiveTransform(point_matrix, converted_points)\n",
    "\n",
    "    warp_perspective = cv2.warpPerspective(img, perspective_transform, (width, height))\n",
    "\n",
    "    resize = resize_with_aspect_ratio(img, 300, 200)\n",
    "    cv2.imshow(\"warp perspective corners\", resize)\n",
    "    return warp_perspective"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_gray = False\n",
    "apply_clahe = True\n",
    "\n",
    "# BASE_FP ..\\static\\\n",
    "fp = BASE_FP + \"boiling-crab.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name = fp.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "event_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_gray:\n",
    "    ...\n",
    "\n",
    "elif apply_clahe:\n",
    "    original = cv2.imread(fp)\n",
    "    imgs[\"original\"] = original\n",
    "\n",
    "    gray = grayscale(original)\n",
    "    imgs[\"gray\"] = gray\n",
    "\n",
    "    # clahe() needs a grayscale img\n",
    "    clahe_ = clahe(gray, 8.0, (8, 8))\n",
    "    imgs[\"clahe\"] = clahe_\n",
    "\n",
    "    blur = cv2.GaussianBlur(clahe_, (51,51), 0)\n",
    "    imgs[\"blur\"] = blur\n",
    "\n",
    "    _, bw = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    imgs[\"bw\"] = bw\n",
    "\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    morph = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)\n",
    "    imgs[\"morphology\"] = morph\n",
    "\n",
    "    corners = find_corners(morph, imgs[\"original\"])\n",
    "    print(corners)\n",
    "    if len(corners) > 4:\n",
    "        corners = best_corners_angle(corners)\n",
    "        print(f\"corners after angle: {corners}\")\n",
    "    elif len(corners) < 4:\n",
    "        print(f\"Found less than 3 corners\")\n",
    "    corners = order_points(corners)\n",
    "\n",
    "    warp = warp_perspective(original, corners)\n",
    "    imgs[\"warp\"] = warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all imgs into separate windows\n",
    "for name, img in imgs.items():\n",
    "    # if \"warp\" in name:\n",
    "    #     resize = resize_window(img, 600, 800, \"warp\")\n",
    "    #     cv2.imshow(name, resize)\n",
    "    # else:\n",
    "    #     resize = resize_with_aspect_ratio(img, 300, 200)\n",
    "    #     cv2.imshow(name, resize)\n",
    "    print(f\"{name}: {img.shape}\")\n",
    "    resize = resize_with_aspect_ratio(img, 400, 200)\n",
    "    cv2.imshow(name, resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(f\"static/changes/{event_name}.warped.JPG\", warp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0036538643ca0742396b75414f464aa148a83f345cf3ded77055a820760bd801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
